{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model= VGG16(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dropout(0.5)(x)\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dropout(0.5)(x)\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "x=Dropout(0.5)(x)\n",
    "x=Dense(256,activation='relu')(x) #dense layer 4\n",
    "x=Dropout(0.5)(x)\n",
    "x=Dense(128,activation='relu')(x) #dense layer 5\n",
    "preds=Dense(8,activation='softmax')(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_path = 'faces-jpg'\n",
    "train_datagen = ImageDataGenerator() #included in our dependencies\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(emotions_path,\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 save_to_dir='keras-faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "model._make_predict_function()\n",
    "\n",
    "step_size_train=train_generator.n\n",
    "model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('vgg16-em.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('vgg16-em.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import face_recognition\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "categories = [\"Neutral\", \"Happy\", \"Sad\", \"Surpiced\", \"Anger\", \"Disgust\", \"Fear\",  \"\", \"\",\"Kiss\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_face_image(image):\n",
    "    img = cv2.imread(os.path.join(dir_path, file_name))\n",
    "    face_location = face_recognition.face_locations(img)[0]\n",
    "    top, right, bottom, left = face_location\n",
    "    return img[top:bottom, left:right]\n",
    "\n",
    "def prepare_model_image(image, w=224, h=224):\n",
    "    face_image = find_face_image(image)\n",
    "    img = np.array(cv2.resize(face_image, (w,h)))\n",
    "    img = np.expand_dims(img, 0)\n",
    "    print(img.shape)\n",
    "    return img\n",
    "\n",
    "def place_text_on_image(image, text):\n",
    "    textsize = cv2.getTextSize(text, font, 3, 2)[0]\n",
    "    textX = int((image.shape[1] - textsize[0]) / 2)\n",
    "    textY = int(image.shape[0] - textsize[1])\n",
    "    cv2.putText(image, text, (textX, textY), font, 3, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "def predict_and_sign(image):\n",
    "    image2 = prepare_model_image(image)\n",
    "    pred_class = categories[np.argmax(model.predict(image2))]\n",
    "    place_text_on_image(image, pred_class)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_detection():\n",
    "    out2 = cv2.VideoWriter('output_auth.avi', fourcc, 20.0, (640,480))\n",
    "    cap2 = cv2.VideoCapture('output.avi')         \n",
    "    for i in tqdm(range(0,100)):\n",
    "        ret,frame = cap2.read()\n",
    "        out2.write(predict_and_sign(frame))\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap2.release()\n",
    "    out2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(frames = 100):\n",
    "    out1 = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480))\n",
    "    cap1 = cv2.VideoCapture(0) \n",
    "    for i in tqdm(range(0, frames)):\n",
    "        ret,frame = cap1.read()\n",
    "        out1.write(frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap1.release()\n",
    "    out1.release()\n",
    "    cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"Pawel.jpg\")\n",
    "image2 = prepare_model_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred class Neutral\n"
     ]
    }
   ],
   "source": [
    "pred_class = categories[np.argmax(model.predict(image2))]\n",
    "print('Pred class', pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_text_on_image(image, pred_class)\n",
    "cv2.imwrite('sample.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dlib' has no attribute 'DLIB_USE_CUDA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4fdcdc12aa0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDLIB_USE_CUDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dlib' has no attribute 'DLIB_USE_CUDA'"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "dlib.DLIB_USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
